{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openai\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('assets/isbsg_dataset.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the specified columns\n",
    "columns_to_drop = [\n",
    "    \"Data Quality Rating\", \"UFP rating\", \"Count Approach\", \"Relative Size\", \n",
    "    \"Value Adjustment Factor\", \"Normalised Work Effort Level 1\", \"Summary Work Effort\", \n",
    "    \"Normalised PDR (ufp)\", \"Pre 2002 PDR\", \"Total project cost\", \"Cost currency\"\n",
    "]\n",
    "\n",
    "df = df.drop(columns=columns_to_drop)\n",
    "\n",
    "# Update \"Sprints / iterations\" values based on \"Development Methodologies\"\n",
    "df['Sprints / iterations'] = df.apply(\n",
    "    lambda row: 1 if 'waterfall' in str(row['Development Methodologies']).lower() else row['Sprints / iterations'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Identify numerical and categorical columns\n",
    "numerical_columns = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_columns = df.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "# Fill missing values for numerical columns with the mean\n",
    "df[numerical_columns] = df[numerical_columns].fillna(df[numerical_columns].mean())\n",
    "\n",
    "# Fill missing values for categorical columns with the mode\n",
    "df[categorical_columns] = df[categorical_columns].fillna(df[categorical_columns].mode().iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_functions.project_description import create_project_description\n",
    "\n",
    "df['project_description'] = df.apply(create_project_description, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings: 100%|██████████| 339/339 [17:29<00:00,  3.10s/it]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def get_embeddings(text_list, model=\"text-embedding-3-large\", batch_size=20):\n",
    "    \"\"\"Generates embeddings in batches to improve efficiency.\"\"\"\n",
    "    embeddings = []\n",
    "    \n",
    "    for i in tqdm(range(0, len(text_list), batch_size), desc=\"Generating embeddings\"):\n",
    "        batch = text_list[i : i + batch_size]\n",
    "        try:\n",
    "            response = openai.embeddings.create(input=batch, model=model)\n",
    "            batch_embeddings = [item.embedding for item in response.data]\n",
    "        except Exception as e:\n",
    "            print(f\"Error generating embeddings: {e}\")\n",
    "            batch_embeddings = [None] * len(batch)  # Avoid breaking process\n",
    "        \n",
    "        embeddings.extend(batch_embeddings)\n",
    "        time.sleep(1)  # Small delay to prevent rate limiting\n",
    "    \n",
    "    return embeddings\n",
    "\n",
    "# Apply batch processing\n",
    "df['embedding'] = get_embeddings(df['project_description'].tolist())\n",
    "\n",
    "# Save embeddings\n",
    "df.to_pickle('isbsg_with_embeddings.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataframe with stored embeddings\n",
    "df = pd.read_pickle('isbsg_with_embeddings.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "\n",
    "# Initialize ChromaDB client with persistent storage\n",
    "chroma_client = chromadb.PersistentClient(path=\"./chroma_db\")\n",
    "\n",
    "# Create or get the collection (without OpenAI embedding function since we already have embeddings)\n",
    "collection = chroma_client.get_or_create_collection(name=\"isbsg_projects\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert embeddings to a list and store in ChromaDB\n",
    "for index, row in df.iterrows():\n",
    "    collection.add(\n",
    "        ids=[str(index)],  # Use index as unique ID\n",
    "        embeddings=[row[\"embedding\"]],  # Use stored embedding\n",
    "        metadatas=[{key: row[key] for key in df.columns if key not in [\"project_description\", \"embedding\"]}],  # Store metadata\n",
    "        documents=[row[\"project_description\"]]  # Store project description\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
